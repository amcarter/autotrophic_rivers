Rprob <- runif(1)
chain[i,] <- if(R < Rprob) {chain[i-1,]} else {pstar} # Should I stay or should I go?
}
# check the acceptance rate, it should be around 0.2
acceptance <- 1 - mean(duplicated(chain[,1]))
acceptance
# plot the chains
par(mfrow = c(3,1), mar = c(2,4,1,1))
plot(chain[,1], type = 'l', ylab = 'b0')
plot(chain[,2], type = 'l', ylab = 'b1')
plot(chain[,3], type = 'l', ylab = 'sigma')
chain2 <- chain[100:nrow(chain),]
par(mfrow = c(1,3), mar = c(4,3,3,1))
plot(density(chain2[,1]), main = 'b0')
abline(v = b0, col = 2)
legend('topleft', c('posterior', 'known value'),
lty = c(1,1), col = c(1,2), bty = 'n')
plot(density(chain2[,2]), main = 'b1')
abline(v = b1, col = 2)
plot(density(chain2[,3]), main = 'sigma')
abline(v = sigma, col = 2)
# fake data
b0 <- 2
b1 <- 5
sigma <- 0.5
n <- 100
x <- -20:20
y <-  b0 + b1 * x + rnorm(length(x),0, exp(sigma))
par(mfrow = c(1,1), mar = c(3,3,1,1))
plot(x,y)
b1 <- 1
sigma <- 0.5
n <- 100
x <- -20:20
y <-  b0 + b1 * x + rnorm(length(x),0, exp(sigma))
par(mfrow = c(1,1), mar = c(3,3,1,1))
plot(x,y)
P <- c(b0, b1, sigma)
# calculate posterior probability
regpost <- function(P, y, x){
# set prior distributions
bo_prior <- dnorm(P[1], 0, 10, log = T)
b1_prior <- dnorm(P[2], 0, 10, log = T)
sigma_prior <- dnorm(P[3], 0, 1, log = T)
yhat <- P[1] + P[2]*x
likelihood <- sum(dnorm(y, yhat, exp(P[3]), log = T))
post <- likelihood + bo_prior + b1_prior + sigma_prior
return(post)
}
chain <- matrix(nrow = 10000, ncol = 3) # empty matrix
scale <- .08 # sets width of proposal distribution. Vary this until the acceptance rate is ~ 0.2
chain[1,] <- c(0,0,0) # starting point for the search
for(i in 2:length(chain[,1])){
pstar <- rnorm(3, chain[i-1,], scale) # calc a proposal set of parameters
poststar <- regpost(pstar, y, x) # calculate [y|theta]*
postchain <- regpost(chain[i-1,], y, x) #calculate [y|theta] for the last step in the chain
R <- exp(poststar - postchain) # remember that posterior function gives log probability!
Rprob <- runif(1)
chain[i,] <- if(R < Rprob) {chain[i-1,]} else {pstar} # Should I stay or should I go?
}
# check the acceptance rate, it should be around 0.2
acceptance <- 1 - mean(duplicated(chain[,1]))
acceptance
# plot the chains
par(mfrow = c(3,1), mar = c(2,4,1,1))
plot(chain[,1], type = 'l', ylab = 'b0')
plot(chain[,2], type = 'l', ylab = 'b1')
plot(chain[,3], type = 'l', ylab = 'sigma')
chain2 <- chain[100:nrow(chain),]
par(mfrow = c(1,3), mar = c(4,3,3,1))
plot(density(chain2[,1]), main = 'b0')
abline(v = b0, col = 2)
legend('topleft', c('posterior', 'known value'),
lty = c(1,1), col = c(1,2), bty = 'n')
plot(density(chain2[,2]), main = 'b1')
abline(v = b1, col = 2)
plot(density(chain2[,3]), main = 'sigma')
abline(v = sigma, col = 2)
# calculate the 95% credible interval
b0_CI <- quantile(chain2[,1], c(0.025, 0.5, 0.975))
b1_CI <- quantile(chain2[,2], c(0.025, 0.5, 0.975))
b0_CI
b1_CI
chain <- matrix(nrow = 1000, ncol = 3) # empty matrix
scale <- .08 # sets width of proposal distribution. Vary this until the acceptance rate is ~ 0.2
chain[1,] <- c(0,0,0) # starting point for the search
for(i in 2:length(chain[,1])){
pstar <- rnorm(3, chain[i-1,], scale) # calc a proposal set of parameters
poststar <- regpost(pstar, y, x) # calculate [y|theta]*
postchain <- regpost(chain[i-1,], y, x) #calculate [y|theta] for the last step in the chain
R <- exp(poststar - postchain) # remember that posterior function gives log probability!
Rprob <- runif(1)
chain[i,] <- if(R < Rprob) {chain[i-1,]} else {pstar} # Should I stay or should I go?
}
# check the acceptance rate, it should be around 0.2
acceptance <- 1 - mean(duplicated(chain[,1]))
acceptance
# plot the chains
par(mfrow = c(3,1), mar = c(2,4,1,1))
plot(chain[,1], type = 'l', ylab = 'b0')
plot(chain[,2], type = 'l', ylab = 'b1')
plot(chain[,3], type = 'l', ylab = 'sigma')
chain2 <- chain[100:nrow(chain),]
par(mfrow = c(1,3), mar = c(4,3,3,1))
plot(density(chain2[,1]), main = 'b0')
abline(v = b0, col = 2)
legend('topleft', c('posterior', 'known value'),
lty = c(1,1), col = c(1,2), bty = 'n')
plot(density(chain2[,2]), main = 'b1')
abline(v = b1, col = 2)
plot(density(chain2[,3]), main = 'sigma')
abline(v = sigma, col = 2)
# calculate the 95% credible interval
b0_CI <- quantile(chain2[,1], c(0.025, 0.5, 0.975))
b1_CI <- quantile(chain2[,2], c(0.025, 0.5, 0.975))
par(mfrow = c(1,1))
plot(chain2[,1], chain2[,2], pch = 19, xlab = 'slope', ylab = 'intercept')
par(mfrow = c(1,1), mar = c(3,3,2,2))
plot(chain2[,1], chain2[,2], pch = 19, xlab = 'slope', ylab = 'intercept')
par(mfrow = c(1,1), mar = c(4,4,2,2))
plot(chain2[,1], chain2[,2], pch = 19, xlab = 'slope', ylab = 'intercept')
# fake data
b0 <- 2
b1 <- 1
sigma <- 0.5
n <- 100
x <- -20:20
y <-  b0 + b1 * x + rnorm(length(x),0, exp(sigma))
par(mfrow = c(1,1), mar = c(3,3,1,1))
plot(x,y)
x <- 1:20
log(3)
# fake data
b0 <- 5
b1 <- 1
sigma <- 1
x <- 1:20
y <-  b0 + b1 * x + rnorm(length(x),0, exp(sigma))
par(mfrow = c(1,1), mar = c(3,3,1,1))
plot(x,y)
P <- c(b0, b1, sigma)
# calculate posterior probability
regpost <- function(P, y, x){
# set prior distributions
bo_prior <- dnorm(P[1], 0, 10, log = T)
b1_prior <- dnorm(P[2], 0, 10, log = T)
sigma_prior <- dnorm(P[3], 0, 1, log = T)
yhat <- P[1] + P[2]*x
likelihood <- sum(dnorm(y, yhat, exp(P[3]), log = T))
post <- likelihood + bo_prior + b1_prior + sigma_prior
return(post)
}
### MCMC code
```{r}
chain <- matrix(nrow = 1000, ncol = 3) # empty matrix
scale <- .08 # sets width of proposal distribution. Vary this until the acceptance rate is ~ 0.2
chain[1,] <- c(0,0,0) # starting point for the search
for(i in 2:length(chain[,1])){
pstar <- rnorm(3, chain[i-1,], scale) # calc a proposal set of parameters
poststar <- regpost(pstar, y, x) # calculate [y|theta]*
postchain <- regpost(chain[i-1,], y, x) #calculate [y|theta] for the last step in the chain
R <- exp(poststar - postchain) # remember that posterior function gives log probability!
Rprob <- runif(1)
chain[i,] <- if(R < Rprob) {chain[i-1,]} else {pstar} # Should I stay or should I go?
}
P <- c(b0, b1, sigma)
# calculate posterior probability
regpost <- function(P, y, x){
# set prior distributions
bo_prior <- dnorm(P[1], 0, 10, log = T)
b1_prior <- dnorm(P[2], 0, 10, log = T)
sigma_prior <- dnorm(P[3], 0, 1, log = T)
yhat <- P[1] + P[2]*x
likelihood <- sum(dnorm(y, yhat, exp(P[3]), log = T))
post <- likelihood + bo_prior + b1_prior + sigma_prior
return(post)
}
chain <- matrix(nrow = 1000, ncol = 3) # empty matrix
scale <- .08 # sets width of proposal distribution. Vary this until the acceptance rate is ~ 0.2
chain[1,] <- c(0,0,0) # starting point for the search
for(i in 2:length(chain[,1])){
pstar <- rnorm(3, chain[i-1,], scale) # calc a proposal set of parameters
poststar <- regpost(pstar, y, x) # calculate [y|theta]*
postchain <- regpost(chain[i-1,], y, x) #calculate [y|theta] for the last step in the chain
R <- exp(poststar - postchain) # remember that posterior function gives log probability!
Rprob <- runif(1)
chain[i,] <- if(R < Rprob) {chain[i-1,]} else {pstar} # Should I stay or should I go?
}
# check the acceptance rate, it should be around 0.2
acceptance <- 1 - mean(duplicated(chain[,1]))
acceptance
scale <- .4 # sets width of proposal distribution. Vary this until the acceptance rate is ~ 0.2
for(i in 2:length(chain[,1])){
pstar <- rnorm(3, chain[i-1,], scale) # calc a proposal set of parameters
poststar <- regpost(pstar, y, x) # calculate [y|theta]*
postchain <- regpost(chain[i-1,], y, x) #calculate [y|theta] for the last step in the chain
R <- exp(poststar - postchain) # remember that posterior function gives log probability!
Rprob <- runif(1)
chain[i,] <- if(R < Rprob) {chain[i-1,]} else {pstar} # Should I stay or should I go?
}
# check the acceptance rate, it should be around 0.2
acceptance <- 1 - mean(duplicated(chain[,1]))
acceptance
chain <- matrix(nrow = 1000, ncol = 3) # empty matrix
scale <- .2 # sets width of proposal distribution. Vary this until the acceptance rate is ~ 0.2
chain[1,] <- c(0,0,0) # starting point for the search
for(i in 2:length(chain[,1])){
pstar <- rnorm(3, chain[i-1,], scale) # calc a proposal set of parameters
poststar <- regpost(pstar, y, x) # calculate [y|theta]*
postchain <- regpost(chain[i-1,], y, x) #calculate [y|theta] for the last step in the chain
R <- exp(poststar - postchain) # remember that posterior function gives log probability!
Rprob <- runif(1)
chain[i,] <- if(R < Rprob) {chain[i-1,]} else {pstar} # Should I stay or should I go?
}
# check the acceptance rate, it should be around 0.2
acceptance <- 1 - mean(duplicated(chain[,1]))
acceptance
# plot the chains
par(mfrow = c(3,1), mar = c(2,4,1,1))
plot(chain[,1], type = 'l', ylab = 'b0')
plot(chain[,2], type = 'l', ylab = 'b1')
plot(chain[,3], type = 'l', ylab = 'sigma')
chain <- matrix(nrow = 10000, ncol = 3) # empty matrix
scale <- .2 # sets width of proposal distribution. Vary this until the acceptance rate is ~ 0.2
chain[1,] <- c(0,0,0) # starting point for the search
for(i in 2:length(chain[,1])){
pstar <- rnorm(3, chain[i-1,], scale) # calc a proposal set of parameters
poststar <- regpost(pstar, y, x) # calculate [y|theta]*
postchain <- regpost(chain[i-1,], y, x) #calculate [y|theta] for the last step in the chain
R <- exp(poststar - postchain) # remember that posterior function gives log probability!
Rprob <- runif(1)
chain[i,] <- if(R < Rprob) {chain[i-1,]} else {pstar} # Should I stay or should I go?
}
# check the acceptance rate, it should be around 0.2
acceptance <- 1 - mean(duplicated(chain[,1]))
acceptance
# plot the chains
par(mfrow = c(3,1), mar = c(2,4,1,1))
plot(chain[,1], type = 'l', ylab = 'b0')
plot(chain[,2], type = 'l', ylab = 'b1')
plot(chain[,3], type = 'l', ylab = 'sigma')
chain2 <- chain[100:nrow(chain),]
par(mfrow = c(1,3), mar = c(4,3,3,1))
plot(density(chain2[,1]), main = 'b0')
abline(v = b0, col = 2)
legend('topleft', c('posterior', 'known value'),
lty = c(1,1), col = c(1,2), bty = 'n')
plot(density(chain2[,2]), main = 'b1')
abline(v = b1, col = 2)
plot(density(chain2[,3]), main = 'sigma')
abline(v = sigma, col = 2)
# calculate the 95% credible interval
b0_CI <- quantile(chain2[,1], c(0.025, 0.5, 0.975))
b1_CI <- quantile(chain2[,2], c(0.025, 0.5, 0.975))
b0_CI
b1_CI
mod <- lm(y~x)
mod
par(mfrow = c(1,1), mar = c(4,4,2,2))
plot(chain2[,1], chain2[,2], pch = 19, xlab = 'slope', ylab = 'intercept')
chain2 <- chain[1000:nrow(chain),]
par(mfrow = c(1,3), mar = c(4,3,3,1))
plot(density(chain2[,1]), main = 'b0')
abline(v = b0, col = 2)
legend('topleft', c('posterior', 'known value'),
lty = c(1,1), col = c(1,2), bty = 'n')
plot(density(chain2[,2]), main = 'b1')
abline(v = b1, col = 2)
plot(density(chain2[,3]), main = 'sigma')
abline(v = sigma, col = 2)
# calculate the 95% credible interval
b0_CI <- quantile(chain2[,1], c(0.025, 0.5, 0.975))
b1_CI <- quantile(chain2[,2], c(0.025, 0.5, 0.975))
mod <- lm(y~x)
b0_CI
b1_CI
mod
par(mfrow = c(1,1), mar = c(4,4,2,2))
plot(chain2[,1], chain2[,2], pch = 19, xlab = 'slope', ylab = 'intercept')
plot(1, xlim = c(1,5), ylim = c(0,3), type = 'n', xlab = 'x', ylab = '[x]')
for(a in c(1,2,3)){
y = a/x^(a+1)
lines(x, y, col = a)
}
x <- seq(1,5, by = 0.1)
plot(1, xlim = c(1,5), ylim = c(0,3), type = 'n', xlab = 'x', ylab = '[x]')
for(a in c(1,2,3)){
y = a/x^(a+1)
lines(x, y, col = a)
}
plot(1, xlim = c(1,5), ylim = c(0,3), type = 'n', xlab = 'x', ylab = '[x]')
for(a in c(1,2,3, 1e50)){
y = a/x^(a+1)
if (a = 1e50) a = 0
lines(x, y, col = a+1)
}
plot(1, xlim = c(1,5), ylim = c(0,3), type = 'n', xlab = 'x', ylab = '[x]')
for(a in c(1,2,3, 1e50)){
y = a/x^(a+1)
if (a == 1e50) a = 0
lines(x, y, col = a+1)
}
legend('topright', c(expression('\alpha = 1 \n \alpha = 2 \n \alpha = 3')))
legend('topright', c('a = 1', 'a = 2', 'a = 3'), lty = c(1,1,1),
col = 1:3, bty = 'n')
x <- seq(1,5, by = 0.1)
plot(1, xlim = c(1,5), ylim = c(0,3), type = 'n', xlab = 'x', ylab = '[x]')
for(a in c(1,2,3)){
y = a/x^(a+1)
lines(x, y, col = a)
}
legend('topright', c('a = 1', 'a = 2', 'a = 3'), lty = c(1,1,1),
col = 1:3, bty = 'n')
options(timeout = 10800)
download.file('https://ral.ucar.edu/sites/default/files/public/product-tool/camels-catchment-attributes-and-meteorology-for-large-sample-studies-dataset-downloads/basin_timeseries_v1p2_metForcing_obsFlow.zip',
destfile = '~/neon_forcings.zip')
library(tidyverse)
getwd()
getwd('~')
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
knitr::opts_knit$set(root.dir = 'C:/Users/Alice Carter/git/autotrophic_rivers/src/')
setwd('C:/Users/Alice Carter/git/autotrophic_rivers/src/')
library(tidyverse)
library(rstan)
library(beepr)
source('stan_helpers.R')
source('SAM/model_helpers.R')
dat <- read_csv('../data/daily_sensor_and_nwis_data_auto.csv')
b <- read_csv('C:/Users/Alice Carter/git/except_heterotrophy/data_356rivers/high_quality_daily_metabolism_with_SP_covariates.rds')
read_csv('C:/Users/Alice Carter/git/except_heterotrophy/data_356rivers/high_quality_daily_metabolism_with_SP_covariates.rds')
b <- readRDS('C:/Users/Alice Carter/git/except_heterotrophy/data_356rivers/high_quality_daily_metabolism_with_SP_covariates.rds')
b
dat
dd <- dat %>%
select(sitecode, date, variable, value) %>%
pivot_wider(names_from = variable, values_from = value)
sites <- unique(dd$sitecode)
md <- read_csv('../data/autotrophic_siteyears_daily_filled_data.csv')
md <- filter(md, sitecode %in% sites)
dd <- select(md, sitecode, Name, date = Date, DOY,
GPP_C_filled, ER_C_filled, slope) %>%
left_join(dd, by = c('sitecode', 'date'))
ss <- dd %>%
filter(sitecode == sites[6])
s <- b %>%
filter(sitecode == sites[6])
head(b)
s <- b %>%
filter(site_name == sites[6])
s
ss
plot(s$date, s$GPP)
lines(ss$date, ss$GPP_C_filled)
lines(s$date, s$GPP_filled)
plot(yourmom)
lolo
md
colnames(s)
sites <- unique(dat$site_name)
dat <- readRDS('C:/Users/Alice Carter/git/except_heterotrophy/data_356rivers/high_quality_daily_metabolism_with_SP_covariates.rds')
sites <- unique(dat$site_name)
sites
md <- read_csv('../data/autotrophic_siteyears_daily_filled_data.csv')
md <- filter(md, sitecode %in% sites)
md
ss
s
dd <- select(md, site_name = sitecode, date = Date, DOY, slope) %>%
left_join(dat, by = c('site_name', 'date'))
md
ggplot(ss, aes(date, GPP, col = site_name))
dat <- readRDS('C:/Users/Alice Carter/git/except_heterotrophy/data_356rivers/high_quality_daily_metabolism_with_SP_covariates.rds')
dat
sites <- unique(dat$site_name)
md <- read_csv('../data/autotrophic_siteyears_daily_filled_data.csv')
md <- filter(md, sitecode %in% sites)
dd <- select(md, site_name = sitecode, date = Date, DOY, slope) %>%
right_join(dat, by = c('site_name', 'date'))
ggplot(ss, aes(date, GPP, col = site_name))
ggplot(dd, aes(date, GPP, col = site_name))
+ geom_line
ggplot(dd, aes(date, GPP, col = site_name))+ geom_line()
unique(dd$site_name)
dd <- select(md, site_name = sitecode, date = Date, Name, DOY, slope) %>%
right_join(dat, by = c('site_name', 'date'))
unique(dd$Name)
ss <- dd %>%
# filter(sitecode == sites[6]) %>%
filter(Name == "CLACKAMAS RIVER NEAR OREGON CITY, OR") %>%
ggplot(aes(date, GPP_C_filled)) + geom_line()
ss <- dd %>%
# filter(sitecode == sites[6]) %>%
filter(Name == "CLACKAMAS RIVER NEAR OREGON CITY, OR") %>%
ggplot(aes(date, GPP)) + geom_line()
ss <- dd %>%
# filter(sitecode == sites[6]) %>%
filter(Name == "CLACKAMAS RIVER NEAR OREGON CITY, OR") %>%
# ggplot(aes(date, GPP)) + geom_line()
arrange(date) %>%
select(sitecode, Name, date, DOY, GPP_C = GPP_C_filled, ER_C = ER_C_filled,
depth = Depth_m, discharge = Discharge_m3s, DO_mgL, light = Light_PAR,
temp_C = WaterTemp_C, slope) %>%
mutate(across(c(-sitecode, -Name, -date, -DOY), zoo::na.approx, na.rm = F),
litter = 1,
tau_mgm2 = 10^3 * depth * slope,
light = light/max(light))
ss <- dd %>%
# filter(sitecode == sites[6]) %>%
filter(Name == "CLACKAMAS RIVER NEAR OREGON CITY, OR") %>%
# ggplot(aes(date, GPP)) + geom_line()
arrange(date) %>%
select(sitecode = site_name, Name, date, DOY, GPP_C = GPP_C_filled, ER_C = ER_C_filled,
depth = Depth_m, discharge = Discharge_m3s, DO_mgL, light = Light_PAR,
temp_C = WaterTemp_C, slope) %>%
mutate(across(c(-sitecode, -Name, -date, -DOY), zoo::na.approx, na.rm = F),
litter = 1,
tau_mgm2 = 10^3 * depth * slope,
light = light/max(light))
dd
dat <- readRDS('C:/Users/Alice Carter/git/except_heterotrophy/data_356rivers/high_quality_daily_metabolism_with_SP_covariates.rds')
colnames(dat)
dd <- select(md, site_name = sitecode, date = Date, Name, slope) %>%
right_join(dat, by = c('site_name', 'date'))
ss <- dd %>%
# filter(sitecode == sites[6]) %>%
filter(Name == "CLACKAMAS RIVER NEAR OREGON CITY, OR") %>%
# ggplot(aes(date, GPP)) + geom_line()
arrange(date) %>%
select(sitecode = site_name, Name, date, DOY, GPP_C = GPP_C_filled, ER_C = ER_C_filled,
depth = Depth_m, discharge = Discharge_m3s, DO_mgL, light = Light_PAR,
temp_C = WaterTemp_C, slope) %>%
mutate(across(c(-sitecode, -Name, -date, -DOY), zoo::na.approx, na.rm = F),
litter = 1,
tau_mgm2 = 10^3 * depth * slope,
light = light/max(light))
ss <- dd %>%
# filter(sitecode == sites[6]) %>%
filter(Name == "CLACKAMAS RIVER NEAR OREGON CITY, OR") %>%
# ggplot(aes(date, GPP)) + geom_line()
arrange(date) %>%
select(sitecode = site_name, Name, date, DOY, GPP, ER,
depth = Depth_m, discharge = Discharge_m3s, DO_mgL, light = Light_PAR,
temp_C = WaterTemp_C, slope) %>%
mutate(across(c(-sitecode, -Name, -date, -DOY), zoo::na.approx, na.rm = F),
litter = 1,
tau_mgm2 = 10^3 * depth * slope,
light = light/max(light))
ss <- dd %>%
# filter(sitecode == sites[6]) %>%
filter(Name == "CLACKAMAS RIVER NEAR OREGON CITY, OR") %>%
# ggplot(aes(date, GPP)) + geom_line()
arrange(date) %>%
select(sitecode = site_name, Name, date, DOY, GPP, ER,
depth, discharge, DO_mgL, light = PAR_sum,
temp_C = temp.water, slope) %>%
mutate(across(c(-sitecode, -Name, -date, -DOY), zoo::na.approx, na.rm = F),
litter = 1,
tau_mgm2 = 10^3 * depth * slope,
light = light/max(light))
ss <- dd %>%
# filter(sitecode == sites[6]) %>%
filter(Name == "CLACKAMAS RIVER NEAR OREGON CITY, OR") %>%
# ggplot(aes(date, GPP)) + geom_line()
arrange(date) %>%
select(sitecode = site_name, Name, date, DOY, GPP, ER,
depth, discharge, DO_mgL= DO.obs, light = PAR_sum,
temp_C = temp.water, slope) %>%
mutate(across(c(-sitecode, -Name, -date, -DOY), zoo::na.approx, na.rm = F),
litter = 1,
tau_mgm2 = 10^3 * depth * slope,
light = light/max(light))
ss %>%
select(date, temp = temp_C, discharge, GPP_C, ER_C, litter) %>%
pivot_longer(-date, names_to = 'variable', values_to = 'value') %>%
ggplot(aes(date, value, col = variable)) +
geom_line() +
facet_wrap(.~variable, nrow = 4, scales = 'free_y')
ss %>%
select(date, temp = temp_C, discharge, GPP, ER, litter) %>%
pivot_longer(-date, names_to = 'variable', values_to = 'value') %>%
ggplot(aes(date, value, col = variable)) +
geom_line() +
facet_wrap(.~variable, nrow = 4, scales = 'free_y')
ss <- dd %>%
# filter(sitecode == sites[6]) %>%
filter(Name == "CLACKAMAS RIVER NEAR OREGON CITY, OR") %>%
# ggplot(aes(date, GPP)) + geom_line()
arrange(date) %>%
select(sitecode = site_name, Name, date, DOY, GPP, ER,
depth, discharge, DO_mgL= DO.obs, light = PAR_sum,LAI = LAI_proc,
temp_C = temp.water, slope) %>%
mutate(across(c(-sitecode, -Name, -date, -DOY), zoo::na.approx, na.rm = F),
litter = calc_litter(500, LAI),
tau_mgm2 = 10^3 * depth * slope,
light = light/max(light))
ss %>%
select(date, temp = temp_C, discharge, GPP, ER, litter) %>%
pivot_longer(-date, names_to = 'variable', values_to = 'value') %>%
ggplot(aes(date, value, col = variable)) +
geom_line() +
facet_wrap(.~variable, nrow = 4, scales = 'free_y')
ss <- dd %>%
# filter(sitecode == sites[6]) %>%
filter(Name == "CLACKAMAS RIVER NEAR OREGON CITY, OR") %>%
# ggplot(aes(date, GPP)) + geom_line()
arrange(date) %>%
select(sitecode = site_name, Name, date, DOY, GPP, ER,
depth, discharge, DO_mgL= DO.obs, light = PAR_sum,LAI = LAI_proc,
temp_C = temp.water, slope) %>%
mutate(across(c(-sitecode, -Name, -date, -DOY), zoo::na.approx, na.rm = F),
tau_mgm2 = 10^3 * depth * slope,
light = light/max(light))
